{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.densenet import DenseNet121_Weights, densenet121\n",
    "from torchvision.models.mobilenetv2 import mobilenet_v2,MobileNet_V2_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising MobileNetV2 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2dNormActivation(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      "  (1): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (4): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (8): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (9): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (12): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (13): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (15): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (17): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (18): Conv2dNormActivation(\n",
      "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mobilenet_v2(MobileNet_V2_Weights).features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original densenet backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_dense = densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size - Part 1: torch.Size([1, 64, 56, 56])\n",
      "Output Size - Part 2: torch.Size([1, 256, 56, 56])\n",
      "Output Size - Part 3: torch.Size([1, 512, 28, 28])\n",
      "Output Size - Part 4: torch.Size([1, 1024, 14, 14])\n",
      "Output Size - Part 5: torch.Size([1, 1024, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "# Pass the input through each part of the model\n",
    "backbones = nn.ModuleList([\n",
    "            backbone_dense[:4],\n",
    "            backbone_dense.denseblock1,\n",
    "            nn.Sequential(\n",
    "                backbone_dense.transition1,\n",
    "                backbone_dense.denseblock2,\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                backbone_dense.transition2,\n",
    "                backbone_dense.denseblock3,\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                backbone_dense.transition3,\n",
    "                backbone_dense.denseblock4,\n",
    "            )\n",
    "        ])\n",
    "output_part_1 = backbones[0](torch.rand(1,3,224,224))  # Output of backbone[:4]\n",
    "output_part_2 = backbones[1](output_part_1)  # Output of backbone.denseblock1\n",
    "output_part_3 = backbones[2](output_part_2)  # Output of transition1 + denseblock2\n",
    "output_part_4 = backbones[3](output_part_3)  # Output of transition2 + denseblock3\n",
    "output_part_5 = backbones[4](output_part_4)  # Output of transition3 + denseblock4\n",
    "\n",
    "# Print the sizes of the outputs\n",
    "print(\"Output Size - Part 1:\", output_part_1.size())\n",
    "print(\"Output Size - Part 2:\", output_part_2.size())\n",
    "print(\"Output Size - Part 3:\", output_part_3.size())\n",
    "print(\"Output Size - Part 4:\", output_part_4.size())\n",
    "print(\"Output Size - Part 5:\", output_part_5.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification made to backbone to use MobilenetV2 instead (The one that is included into retinanet.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_mobile = mobilenet_v2(MobileNet_V2_Weights).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size - Part 1: torch.Size([1, 64, 56, 56])\n",
      "Output Size - Part 2: torch.Size([1, 256, 56, 56])\n",
      "Output Size - Part 3: torch.Size([1, 512, 28, 28])\n",
      "Output Size - Part 4: torch.Size([1, 1024, 14, 14])\n",
      "Output Size - Part 5: torch.Size([1, 1024, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "# Pass the input through each part of the model\n",
    "backbones_mobile = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                backbone_mobile[:3],\n",
    "                nn.Conv2d(24, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0), bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU6(inplace=True)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "                backbone_mobile[3:8],\n",
    "                nn.ConvTranspose2d(64, 256, kernel_size=4, stride=4, padding=0, bias=False)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(256, 64, kernel_size=1, stride=1, padding=0),\n",
    "                backbone_mobile[8:11],\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Conv2d(64, 512, kernel_size=1, stride=1, padding=0),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(512, 64, kernel_size=3, stride=2, padding=1),  # Reduce spatial dimensions to 14x14\n",
    "                nn.ReLU(inplace=True),\n",
    "                backbone_mobile[11:15],\n",
    "                nn.ConvTranspose2d(160, 512, kernel_size=2, stride=2),  # Upsample to 14x14\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(512, 1024, kernel_size=1, stride=1, padding=0),  # 1x1 convolution to change channel size\n",
    "                nn.ReLU(inplace=True)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(1024, 160, kernel_size=2, stride=2),  # Reduce spatial dimensions to 7x7\n",
    "                nn.ReLU(inplace=True),\n",
    "                backbone_mobile[15:],\n",
    "                nn.Conv2d(1280, 1024, kernel_size=1, stride=1, padding=0)\n",
    "                \n",
    "            ) \n",
    "        ])\n",
    "output_part_1 = backbones_mobile[0](torch.rand(1,3,224,224))  \n",
    "output_part_2 = backbones_mobile[1](output_part_1)  \n",
    "output_part_3 = backbones_mobile[2](output_part_2)  \n",
    "output_part_4 = backbones_mobile[3](output_part_3)  \n",
    "output_part_5 = backbones_mobile[4](output_part_4)  \n",
    "\n",
    "# Print the sizes of the outputs\n",
    "print(\"Output Size - Part 1:\", output_part_1.size())\n",
    "print(\"Output Size - Part 2:\", output_part_2.size())\n",
    "print(\"Output Size - Part 3:\", output_part_3.size())\n",
    "print(\"Output Size - Part 4:\", output_part_4.size())\n",
    "print(\"Output Size - Part 5:\", output_part_5.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## original architecture of mobilenetv2 without changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size - Part 1: torch.Size([1, 24, 56, 56])\n",
      "Output Size - Part 2: torch.Size([1, 64, 14, 14])\n",
      "Output Size - Part 3: torch.Size([1, 64, 14, 14])\n",
      "Output Size - Part 4: torch.Size([1, 160, 7, 7])\n",
      "Output Size - Part 5: torch.Size([1, 1280, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "backbones_mobile = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                backbone_mobile[:3],\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                backbone_mobile[3:8],\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                backbone_mobile[8:11],\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                backbone_mobile[11:15],\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                backbone_mobile[15:],\n",
    "            ) \n",
    "        ])\n",
    "output_part_1 = backbones_mobile[0](torch.rand(1,3,224,224))  # Output of backbone[:4]\n",
    "output_part_2 = backbones_mobile[1](output_part_1)  # Output of backbone.denseblock1\n",
    "output_part_3 = backbones_mobile[2](output_part_2)  # Output of transition1 + denseblock2\n",
    "output_part_4 = backbones_mobile[3](output_part_3)  # Output of transition2 + denseblock3\n",
    "output_part_5 = backbones_mobile[4](output_part_4)  # Output of transition3 + denseblock4\n",
    "\n",
    "# Print the sizes of the outputs\n",
    "print(\"Output Size - Part 1:\", output_part_1.size())\n",
    "print(\"Output Size - Part 2:\", output_part_2.size())\n",
    "print(\"Output Size - Part 3:\", output_part_3.size())\n",
    "print(\"Output Size - Part 4:\", output_part_4.size())\n",
    "print(\"Output Size - Part 5:\", output_part_5.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.densenet import DenseNet121_Weights, densenet121\n",
    "from torchvision.models.mobilenetv2 import mobilenet_v2,MobileNet_V2_Weights\n",
    "from prior_box import PriorBox\n",
    "\n",
    "class RetinaNet(nn.Module):\n",
    "\n",
    "    def __init__(self, config, pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Feature Pyramid Network (FPN) with four feature maps of resolutions\n",
    "        # 1/4, 1/8, 1/16, 1/32 and `num_filters` filters for all feature maps.\n",
    "        num_anchors = config.get('num_anchors', 6)\n",
    "        num_filters_fpn = config.get('num_filters_fpn', 128)\n",
    "        self.num_classes = config['num_classes']\n",
    "        fmaps = [56, 56, 28, 14, 7]\n",
    "        self.size = config[\"img_size\"]\n",
    "        self.priorbox = PriorBox(self.size, feature_maps=fmaps)\n",
    "        self.num_anchors = num_anchors\n",
    "        self.fpn = FPN(out_channels=num_anchors * (4 + self.num_classes),backbone='mobilenet_v2')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.priors = self.priorbox.forward()\n",
    "            if torch.cuda.is_available():\n",
    "                self.priors = self.priors.cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        maps = self.fpn(x)\n",
    "        loc = list()\n",
    "        conf = list()\n",
    "        for map in maps:\n",
    "            loc.append(map[:, :self.num_anchors * 4].permute(0, 2, 3, 1).contiguous())\n",
    "            conf.append(map[:, self.num_anchors * 4:].permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
    "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)\n",
    "        output = (\n",
    "            loc.view(loc.size(0), -1, 4),\n",
    "            conf.view(conf.size(0), -1, self.num_classes),\n",
    "            self.priors\n",
    "        )\n",
    "        return output\n",
    "\n",
    "\n",
    "class FPN(nn.Module):\n",
    "\n",
    "    def __init__(self, out_channels, backbone=\"densenet\"):\n",
    "\n",
    "        super().__init__()\n",
    "        self.upsample = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.backbone = backbone\n",
    "        if backbone == \"densenet\":\n",
    "            backbone = densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1).features\n",
    "            self.backbones = nn.ModuleList([\n",
    "                backbone[:4],\n",
    "                backbone.denseblock1,\n",
    "                nn.Sequential(\n",
    "                    backbone.transition1,\n",
    "                    backbone.denseblock2,\n",
    "                ),\n",
    "                nn.Sequential(\n",
    "                    backbone.transition2,\n",
    "                    backbone.denseblock3,\n",
    "                ),\n",
    "                nn.Sequential(\n",
    "                    backbone.transition3,\n",
    "                    backbone.denseblock4,\n",
    "                )\n",
    "            ])\n",
    "            self.enc0_channel = 64\n",
    "            self.enc1_channel = 256\n",
    "            self.enc2_channel = 512\n",
    "            self.enc3_channel = 1024\n",
    "            self.enc4_channel = 1024\n",
    "\n",
    "        elif backbone == \"mobilenet_v2\":\n",
    "            backbone_mobile = mobilenet_v2(MobileNet_V2_Weights).features\n",
    "            self.backbones = nn.ModuleList([\n",
    "                nn.Sequential(\n",
    "                    backbone_mobile[:3], # out channels: 24\n",
    "                ),\n",
    "                nn.Sequential(\n",
    "                    backbone_mobile[3:4], # out channels: 24\n",
    "                ),\n",
    "                nn.Sequential(\n",
    "                    backbone_mobile[4:7], # out channels: 32\n",
    "                ),\n",
    "                nn.Sequential(\n",
    "                    backbone_mobile[7:14], # out channels: 96\n",
    "                ),\n",
    "                nn.Sequential(\n",
    "                    backbone_mobile[14:], # out channels: 1280\n",
    "                )\n",
    "            ])\n",
    "\n",
    "            self.transform_enc4_to_enc3 = nn.Sequential(\n",
    "                torch.nn.Conv2d(1280, 96, kernel_size=1, stride=1, padding=0),\n",
    "                torch.nn.ReLU6(inplace=True)\n",
    "            )\n",
    "\n",
    "            self.enc0_channel = 24\n",
    "            self.enc1_channel = 24\n",
    "            self.enc2_channel = 32\n",
    "            self.enc3_channel = 96\n",
    "            self.enc4_channel = 1280\n",
    "\n",
    "        else:\n",
    "            raise f\"{backbone} not implemented.\"\n",
    "\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.Conv2d(self.enc3_channel, self.enc2_channel, kernel_size=3, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(self.enc2_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.Conv2d(self.enc2_channel, self.enc1_channel, kernel_size=3, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(self.enc1_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.up3 = nn.Sequential(\n",
    "            nn.Conv2d(self.enc1_channel, self.enc0_channel, kernel_size=3, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(self.enc0_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.up4 = nn.Sequential(\n",
    "            nn.Conv2d(self.enc0_channel + self.enc0_channel, self.enc0_channel, kernel_size=3, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(self.enc0_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv0 = nn.Sequential(\n",
    "            nn.Conv2d(self.enc4_channel, out_channels, kernel_size=1),\n",
    "        )\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(self.enc2_channel, out_channels, kernel_size=1),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(self.enc1_channel, out_channels, kernel_size=1),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(self.enc0_channel, out_channels, kernel_size=1),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(self.enc0_channel, out_channels, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Bottom-up pathway, from ResNet\n",
    "        enc0 = self.backbones[0](x)     # bs, channel_enc0, 56, 56\n",
    "        print(enc0.size())\n",
    "        enc1 = self.backbones[1](enc0)  # bs, channel_enc1, 56, 56\n",
    "        print(enc1.size())\n",
    "        enc2 = self.backbones[2](enc1)  # bs, channel_enc2, 28, 28\n",
    "        print(enc2.size())\n",
    "        enc3 = self.backbones[3](enc2)  # bs, channel_enc3, 14, 14\n",
    "        print(enc3.size())\n",
    "        enc4 = self.backbones[4](enc3)  # bs, channel_enc4, 7, 7\n",
    "        print(enc4.size())\n",
    "\n",
    "        up1 = self.upsample(enc4)  # bs, channel_enc4, 14, 14\n",
    "        print(\"HI\")\n",
    "        print(up1.size())\n",
    "        print(enc3.size())\n",
    "        if up1.size(1) != enc3.size(1):\n",
    "            # transform up1's channel size when channel_enc3 != channel_enc4\n",
    "            up1 = self.transform_enc4_to_enc3(up1) + enc3\n",
    "        else:\n",
    "            up1 = up1 + enc3\n",
    "\n",
    "        print(up1.size())\n",
    "        up1 = self.up1(up1)  # bs, channel_enc2, 14, 14\n",
    "        print(\"up1 =\",up1.size())\n",
    "        up2 = self.upsample(up1)  # bs, channel_enc2, 28, 28\n",
    "        up2 = up2 + enc2\n",
    "        up2 = self.up2(up2)  # bs, channel_enc1, 28, 28\n",
    "\n",
    "        up3 = self.upsample(up2)  # bs, channel_enc1, 56, 56\n",
    "        up3 = up3 + enc1\n",
    "        up3 = self.up3(up3)  # bs, channel_enc1, 56, 56\n",
    "\n",
    "        up4 = torch.cat([up3, enc0], 1)  # bs, channel_enc1 + channel_enc0, 56, 56\n",
    "        up4 = self.up4(up4)\n",
    "\n",
    "        map1 = self.conv0(enc4)\n",
    "        map2 = self.conv1(up1)\n",
    "        map3 = self.conv2(up2)\n",
    "        map4 = self.conv3(up3)\n",
    "        map5 = self.conv4(up4)\n",
    "        # for i in [map1, map2, map3, map4, map5]:\n",
    "        #     print(i.size())\n",
    "        return map1, map2, map3, map4, map5\n",
    "\n",
    "\n",
    "def build_retinanet(config):\n",
    "    return nn.DataParallel(RetinaNet(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grego\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\grego\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 32, 28, 28])\n",
      "torch.Size([1, 96, 14, 14])\n",
      "torch.Size([1, 1280, 7, 7])\n",
      "HI\n",
      "torch.Size([1, 1280, 14, 14])\n",
      "torch.Size([1, 96, 14, 14])\n",
      "torch.Size([1, 96, 14, 14])\n",
      "up1 = torch.Size([1, 32, 14, 14])\n",
      "torch.Size([1, 36, 7, 7])\n",
      "torch.Size([1, 36, 14, 14])\n",
      "torch.Size([1, 36, 28, 28])\n",
      "torch.Size([1, 36, 56, 56])\n",
      "torch.Size([1, 36, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "model = FPN(out_channels=6 * (4 + 2), backbone=\"mobilenet_v2\")\n",
    "test_image = torch.rand(1,3,224,224)\n",
    "output_maps = model(test_image)\n",
    "for each_map in output_maps:\n",
    "    print(each_map.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 256, 56, 56])\n",
      "torch.Size([1, 512, 28, 28])\n",
      "torch.Size([1, 1024, 14, 14])\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "HI\n",
      "torch.Size([1, 1024, 14, 14])\n",
      "torch.Size([1, 1024, 14, 14])\n",
      "torch.Size([1, 1024, 14, 14])\n",
      "up1 = torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 36, 7, 7])\n",
      "torch.Size([1, 36, 14, 14])\n",
      "torch.Size([1, 36, 28, 28])\n",
      "torch.Size([1, 36, 56, 56])\n",
      "torch.Size([1, 36, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "model = FPN(out_channels=6 * (4 + 2),backbone=\"densenet\")\n",
    "test_image = torch.rand(1,3,224,224)\n",
    "output_maps = model(test_image)\n",
    "for each_map in output_maps:\n",
    "    print(each_map.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
